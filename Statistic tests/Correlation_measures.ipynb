{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document I would like to introduce a few statistical measures which will helpfull during correlation analysis between continuous or categorical features. First of all I present basic correlation measures like pearson or spearman to calculate relationship between numerical variables. Then I introduce more sophisticated measures and test which we can use during analyze categorical variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przyjęte z góry dopuszczalne ryzyko popelnienia bledu I rodzaju (uznania prawdziwej hipotezy zerowej za falszywa), pozwalajace okreslic powyzej jakich odchylen zaobserwowanych w probie test rozstrzygnie na korzysz hipotezy alternatywnej. Determinuje ryzyku bledu II rodzaju (nieodrzucenia falszywej hipotezy zerowej; jego dopelnieniem jest moc testu). W tym stopniu w jakim rozklady statystyki pokrywaja sie, im surowszy poziom istotnosci tym nizsza moc testu i wieksze ryzyko $\\beta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartosc zalozonego poziomu istotnosci jest porownywalna z wyliczona na podstawie testu statystycznego wartoscia $p$. Jesli wartosc $p$ jest wieksza, rezultaty badania sa niekonkluzywne. W propozycji Neymana-Pearsona, nalezy w tej sytuacji postepowac tak jakby prawdziwa byla hipoteza zerowa (zwykle postuluje brak efektu lub roznic). Nie daje to jednak samodzielnych podstaw do przekonania, ze tak rzeczywiscie jest. Jesli wartosci $p$ jest nizsza mozna postepowac tak jakby prawdziwa byla hipoteza alternatywna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistical hypothesis testing, the p-value or probability value is the probability of obtaining test results at least as extreme as the results actually observed during the test, assuming that the null hypothesis is correct. The use of p-values in statistical hypothesis testing is common in many fields of research such as physics, economics, finance, accounting, political science, psychology, biology, criminal justice, criminology, and sociology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In statistics, every conjecture concerning the unknown distribution F of a random variable X is called a statistical hypothesis. If we state one hypothesis only and the aim of the statistical test is to verify whether this hypothesis is not false, but not, at the same time, to investigate other hypotheses, then such a test is called a significance test. A statistical hypothesis that refers only to the numerical values of unknown parameters of a distribution is called a parametric hypothesis. Methods of verifying statistical hypotheses are called statistical tests. Tests of parametric hypotheses are called parametric tests. We can likewise also have non-parametric hypotheses and non-parametric tests.\n",
    "\n",
    "The p-value is used in the context of null hypothesis testing in order to quantify the idea of statistical significance of evidence. Null hypothesis testing is a reductio ad absurdum argument adapted to statistics. In essence, a claim is assumed valid if its counterclaim is improbable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is widely used in statistical hypothesis testing, specifically in null hypothesis significance testing. In this method, as part of experimental design, before performing the experiment, one first chooses a model (the null hypothesis) and a threshold value for p, called the significance level of the test, traditionally 5% or 1% and denoted as α. If the p-value is less than the chosen significance level (α), that suggests that the observed data is sufficiently inconsistent with the null hypothesis and that the null hypothesis may be rejected. However, that does not prove that the tested hypothesis is true. When the p-value is calculated correctly, this test guarantees that the type I error rate is at most α. For typical analysis, using the standard α = 0.05 cutoff, the null hypothesis is rejected when p < .05 and not rejected when p > .05. The p-value does not, in itself, support reasoning about the probabilities of hypotheses but is only a tool for deciding whether to reject the null hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistic tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Student's t-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## F-test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.array([8.04,6.95,7.58,8.81,8.33,9.96,7.24,4.26,10.84,4.82,5.68])\n",
    "x1=np.array([10,8,13,9,11,14,6,4,12,7,5])\n",
    "x2=np.sqrt(y)+np.random.normal(len(y))\n",
    "X = pd.DataFrame({'x1' : x1, 'x2' : x2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "y_pred = model.predict(X)\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Sum of Square Errors\n",
    "SSE = np.sum(residuals**2)\n",
    "\n",
    "# Residual Standard Error\n",
    "n = len(y)\n",
    "k = len(model.coef_)-1\n",
    "RSE = np.sqrt(SSE/(n - (1 + k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.50221157e-04, 5.32081763e+00])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Error\n",
    "Coef_SE = RSE/np.sqrt(np.sum(X**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    0.004855\n",
       "x2    0.003096\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Coef_SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x1    7.467421\n",
       "x2    0.000582\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t-value\n",
    "RSE/np.sqrt(np.sum((model.coef_*X)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between continuous variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formula**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "a = np.arange(1, 102, 2)\n",
    "b = np.concatenate([np.arange(4, 200, 4), np.arange(1, 100, 50)])\n",
    "pearson = pearsonr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient: \n",
      "0.8248277868549205\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson coefficient: \")\n",
    "print(pearson[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson t-test: \n",
      "9.981149395624778e-14\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson t-test: \")\n",
    "print(pearson[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate mean and standard deviation of variables\n",
    "Ea = np.sum(a)/(len(a)-1)\n",
    "Eb = np.sum(b)/(len(b)-1)\n",
    "std_a = np.std(a, ddof=1)\n",
    "std_b = np.std(b, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Value of a:  52.02\n",
      "Expected Value of b:  99.04\n",
      "Standard deviation of a:  29.732137494637012\n",
      "Standard deviation of b:  58.064190307610694\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected Value of a: \", Ea)\n",
    "print(\"Expected Value of b: \", Eb)\n",
    "print(\"Standard deviation of a: \", std_a)\n",
    "print(\"Standard deviation of b: \", std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Centering variables\n",
    "center_a = np.array([a - Ea])\n",
    "center_b = np.array([b - Eb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2a. Calculate covariance matrix (my own)\n",
    "cov_ab = np.round(np.sum(center_a*center_b)/(len(a)-1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix: \n",
      "1425.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Covariance matrix: \")\n",
    "print(cov_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2b. Calculate covariance matrix (np.cov)\n",
    "cov_ab2 = np.cov(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix: \n",
      "1425.98\n"
     ]
    }
   ],
   "source": [
    "print(\"Covariance matrix: \")\n",
    "print(cov_ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a. Calculate Pearson coefficient \n",
    "pearson = cov_ab/(std_a*std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient: \n",
      "0.8259978703751366\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson coefficient: \")\n",
    "print(pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b. Calculate Pearson coefficient\n",
    "pearson = cov_ab2/(std_a*std_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson coefficient: \n",
      "0.8248277868549206\n"
     ]
    }
   ],
   "source": [
    "print(\"Pearson coefficient: \")\n",
    "print(pearson[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_pearson(a, b):\n",
    "    \n",
    "    # 1. Calculate mean and standard deviation of variables\n",
    "    Ea = np.sum(a)/(len(a)-1)\n",
    "    Eb = np.sum(b)/(len(b)-1)\n",
    "    std_a = np.std(a, ddof=1)\n",
    "    std_b = np.std(b, ddof=1)\n",
    "    \n",
    "    # 2. Calculate covariance matrix (np.cov)\n",
    "    cov_ab = np.cov(a, b)\n",
    "    \n",
    "    # 3a. Calculate Pearson coefficient \n",
    "    pearson = cov_ab/(std_a*std_b)\n",
    "    return pearson[0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intepretation:** Correlation coefficient is equal 0.82 so probably there is significance linear relationship between vectors a and b. Moreover p-value equals to 9.98-14 for null hypothesis that there isn't any linear relationship is very low. In effect we reject null hypothesis for alternative hypothesis that there could be some linear relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spearman Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scipy.spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "a = np.arange(1, 102, 2)\n",
    "b = np.concatenate([np.arange(4, 200, 4), np.arange(1, 100, 50)])\n",
    "spearman = spearmanr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman coefficient: \n",
      "0.8221719457013574\n"
     ]
    }
   ],
   "source": [
    "print(\"Spearman coefficient: \")\n",
    "print(spearman[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman t-test: \n",
      "1.3967399972761245e-13\n"
     ]
    }
   ],
   "source": [
    "print(\"Spearman t-test: \")\n",
    "print(spearman[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Add rangs to a and b variables, sorting a and b variables increasingly\n",
    "df_a = pd.DataFrame({\"rang_a\":np.arange(1, len(a)+1), \"a\":a}).sort_values(\"a\")\n",
    "df_b = pd.DataFrame({\"rang_b\":np.arange(1, len(b)+1), \"b\":b}).sort_values(\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate pearson correlation between sort rang_a and rang_b\n",
    "spearman = my_pearson(df_a.rang_a, df_b.rang_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman coefficient: \n",
      "0.8221719457013574\n"
     ]
    }
   ],
   "source": [
    "print(\"Spearman coefficient: \")\n",
    "print(spearman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kendall Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "# Reationship between categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relationship between categorical and continuous variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point biserial correlation coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description:**\n",
    "(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate _Point biserial correlation_ using two formulas. First uses biased sample variance $s_{n}^{2}$ where formula is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "**Formula [1]:**\n",
    "\\begin{equation}\n",
    "r_{pb} = \\frac{M_{1} - M_{0}}{s_{n}}\\sqrt{\\frac{n_{1}n_{0}}{n^{2}}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$M_{1}$ - mean value of the continuous variable X for all data points in group 1 \n",
    "\n",
    "$M_{0}$ - mean value of the continuous variable X for all data points in group 2 \n",
    "\n",
    "$n_{1}$ - number of data points in group 1\n",
    "\n",
    "$n_{0}$ - number of data points in group 2\n",
    "\n",
    "$n$ - total number of data points "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second method uses unbiased sample variance and this formula is implemented in scipy module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formula [2]:**\n",
    "\\begin{equation}\n",
    "r_{pb} = \\frac{M_{1} - M_{0}}{s_{n-1}}\\sqrt{\\frac{n_{1}n_{0}}{n(n-1)}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For calculate significance of correlation coefficient we can use t-test (similar like for Pearson coefficient). Then we followes Student's t-distribution with (n - 2) degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Hypothesis:** \n",
    "\n",
    "$H_{0}$: correlation is equal to zero in the population \\\n",
    "$H_{A}$: correlation is different from zero    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_poinbiserialr(a, b):\n",
    "    \n",
    "    # Condition\n",
    "    if len(a) != len(b):\n",
    "        print(\"Array 'a' and 'b' aren't equal lengths.\")\n",
    "    if len(np.unique(a)) != 2:\n",
    "        print(\"Array 'a' have to be categorical variable with only 2 state.\")\n",
    "    \n",
    "    # Calculation\n",
    "    df = pd.DataFrame({'a': a, 'b': b})\n",
    "   \n",
    "    m1 = np.mean(np.array(df.loc[df.a == 1, :].b))\n",
    "    m0 = np.mean(np.array(df.loc[df.a == 0, :].b))\n",
    "    sn = np.std(b, ddof=1)\n",
    "    n1 = len(np.array(df.loc[df.a == 1, :]))\n",
    "    n0 = len(np.array(df.loc[df.a == 0, :]))\n",
    "    n = df.shape[0]\n",
    "    \n",
    "    # Formula\n",
    "    r = ((m1 - m0)/sn)*np.sqrt((n1*n0)/(n*(n-1)))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test_t(n, coef):\n",
    "    \n",
    "    # Calculation\n",
    "    results = coef * np.sqrt((n-2)/(1-coef**2))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointbiserialrResult(correlation=0.0462096115864626, pvalue=0.14422724508867713)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pointbiserialr \n",
    "\n",
    "a = np.random.binomial(1, 0.5, 1000)\n",
    "b = np.random.normal(0, 1, 1000)\n",
    "pointbiserialr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point Biserial Correlation Coefficient: 0.0462096115864626\n",
      "t-test: 1.4613753082171197\n"
     ]
    }
   ],
   "source": [
    "r = my_poinbiserialr(a, b)\n",
    "r_test = my_test_t(n = len(a), coef = r)\n",
    "\n",
    "print(\"Point Biserial Correlation Coefficient:\", r)\n",
    "print(\"t-test:\", r_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PointbiserialrResult(correlation=-0.8660687083024938, pvalue=2.876775827484165e-31)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([np.random.binomial(n = 1, p = 1, size = 50), np.random.binomial(n = 1, p = 0, size = 50)]).reshape((100, ))\n",
    "b = np.arange(100)\n",
    "pointbiserialr(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8660687083024938"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_poinbiserialr(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal - Walls H test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_{0}$ - the population median of all of the groups are equal,\n",
    "\n",
    "$H_{A}$ - at least one of the population median of all of the groups are not equal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median of x1: -0.016002055277683554 , Standard Deviation: 1.060023233228567\n",
      "Median of x2: 0.0808067794464309 , Standard Deviation: 1.028357380582814\n",
      "Median of x3: 0.7591585145276174 , Standard Deviation: 0.9945053970020833\n",
      "Test statistic: 57.49357342192695 , p-value: 3.276643246671002e-13\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "x1 = np.random.normal(0, 1, 100)\n",
    "x2 = np.random.normal(0, 1, 100)\n",
    "x3 = np.random.exponential(1, 100)\n",
    "kw_test = kruskal(x1, x2, x3)\n",
    "\n",
    "print(\"Median of x1:\", np.median(x1), \", Standard Deviation:\", np.std(x1))\n",
    "print(\"Median of x2:\", np.median(x2), \", Standard Deviation:\", np.std(x2))\n",
    "print(\"Median of x3:\", np.median(x3), \", Standard Deviation:\", np.std(x3))\n",
    "print(\"Test statistic:\", kw_test.statistic, \", p-value:\", kw_test.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KruskalResult(statistic=57.49357342192695, pvalue=3.276643246671002e-13)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
